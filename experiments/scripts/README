[First]
132 x 132 png files, WITHOUT any standalone '1_x' images
==========================
png pixel size 132
train_size 3730
test_size 3169
anchor_size [8, 16, 32]
feature stride size [16,]
logfile slurm-2153455.out, slurm-2155783.out, slurm-2156848.out

[Second]
132 x 132 png files, plus additional 3845 standalone '1_x' images,
all of which are added to the training set (trainsecond.txt). Thus,
trainsecond.txt = train.txt + additional_3845
The testing set remains the same (test.txt)
==========================
png pixel size 132
train_size 3730 + 3845 = 7575
test_size 3169
anchor_size [8, 16, 32]
feature stride size [16,]
logfile slurm-2160201.out, slurm-2163383.out

[Third]
132 x 132 png files, plus additional 3845 '1_x' images, 2411 of which are added
to the training set (trainthird.txt), and 1434 of which are added to the
testing set (testthird.txt).
==========================
png pixel size 132
train_size 3730 + 2411 = 6141
test_size 3169 + 1434 = 4603
anchor_size [8, 16, 32]
feature stride size [16,]
logfile slurm-2163554.out, slurm-2164344.out

[Thirdsmall]
The same as [Third] except that using a smaller anchor scale and a smaller
feature stride size. Training set becomes (trainthirdsmall.txt), which is just
a symbolic link pointing to trainthird.txt. The reason is only to make the name
different to the system. Testing set (testthirdsmall.txt) is also a symbolic
link to testthird.txt
============================
png pixel size 132
train_size 3730 + 2411 = 6141
test_size 3169 + 1434 = 4603
anchor_size [2, 4, 8]
feature stride size [4,]
logfile slurm-2164121.out, slurm-2165140.out
no result

[Fourth]
500 x 500 png files, plus additional 3845 '1_x' images, 2411 of which are added
to the training set (trainfourth.txt), and 1434 of which are added to the
testing set (trainfourth.txt).
============================
png pixel size 500
train_size 3730 + 2411 = 6141
test_size 3169 + 1434 = 4603
anchor_size [8, 16, 32]
feature stride size [16,]

AP for 1_1 = 0.5265
AP for 1_2 = 0.1275
AP for 1_3 = 0.1919
AP for 2_2 = 0.4597
AP for 2_3 = 0.4076
AP for 3_3 = 0.5094
Mean AP = 0.3704
~~~~~~~~
Results:
0.527
0.127
0.192
0.460
0.408
0.509
0.370
~~~~~~~~

[Fifth]
132 png files
components-based bbox,
change config to 132 x 132
70000 iterations
No result
anchor_size [2, 4, 8]
feature stride size [16,]

[Sixth]
132 png files
anchor_size [2, 4, 8]
feature stride size [16,]
ra-dec bbox,
change config to 132 x 132
140000 iterations
No result

[07]
132 png file
anchor_size [8, 16, 32]
feature stride size [16,]
used the ra-dec bbox with adjustment
trainable = True for low-level ConvNets
but change the side back to s=600
currently in the third round of training after (110K iterations, 24 hours)

test07_2nd (110k iterations)
AP for 1_1 = 0.3915
AP for 1_2 = 0.4812
AP for 1_3 = 0.7695
AP for 2_2 = 0.4841
AP for 2_3 = 0.4449
AP for 3_3 = 0.6207
Mean AP = 0.5320

test07_3rd (160k iterations)
AP for 1_1 = 0.3914
AP for 1_2 = 0.4932
AP for 1_3 = 0.7830
AP for 2_2 = 0.4880
AP for 2_3 = 0.4913
AP for 3_3 = 0.4794
Mean AP = 0.5210

[08]
change side to s=132 again
anchor_size [2, 4, 8]
feature stride size [16,]
It still uses z-scale

[09]
s=600
THe same as 07 except it uses logminmax scaled png directly from FITS
After 55K iterations
AP for 1_1 = 0.3769
AP for 1_2 = 0.5523
AP for 1_3 = 0.7012
AP for 2_2 = 0.3207
AP for 2_3 = 0.4410
AP for 3_3 = 0.6884
Mean AP = 0.5134

[10]
change to the new mean based on log_minmax scale  (235, 128, 24)
similar to 09, it uses log_minmax scaled png
similar to 08, it uses s=132
Does not work!

[11]
The same as 10, BUT with s=600
AP for 1_1 = 0.3701
AP for 1_2 = 0.4665
AP for 1_3 = 0.6128
AP for 2_2 = 0.2377
AP for 2_3 = 0.4292
AP for 3_3 = 0.6339
Mean AP = 0.4584

[12]
The same as 11, BUT
anchor_scales=[1, 2, 4, 8, 16, 32]
anchor_ratios=[1]
RPN_BATCHSIZE is still 256
55K iterations:
-------------------
AP for 1_1 = 0.5186
AP for 1_2 = 0.5417
AP for 1_3 = 0.6363
AP for 2_2 = 0.3562
AP for 2_3 = 0.4369
AP for 3_3 = 0.5244
Mean AP = 0.5023

105K Iterations (with a starting LR 0.001 for the second round)
-------------------
AP for 1_1 = 0.2887
AP for 1_2 = 0.6552
AP for 1_3 = 0.7526
AP for 2_2 = 0.5021
AP for 2_3 = 0.5364
AP for 3_3 = 0.7506
Mean AP = 0.5809

100K Iterations (with a starting LR 0.0001 for the second round)
???

[13]
The same as [12] but loading the original VGGnet feature ConvNet
low_level_trainable is still TRUE
50K iteration
AP for 1_1 = 0.5088
AP for 1_2 = 0.7385
AP for 1_3 = 0.8281
AP for 2_2 = 0.5242
AP for 2_3 = 0.6716
AP for 3_3 = 0.7821
Mean AP = 0.6755

100K iteration (with a starting LR 0.0001)
AP for 1_1 = 0.4789
AP for 1_2 = 0.7137
AP for 1_3 = 0.8989
AP for 2_2 = 0.7050
AP for 2_3 = 0.7712
AP for 3_3 = 0.9068
Mean AP = 0.7458

[13.1]
do not load pretrained weights for fc6 and fc7 (Skipping)
not running yet

[14]
The same as [13] but loading the original VGGnet feature ConvNet
low_level_trainable is set to FALSE
do not skip fc6 and fc7
70K iteration
AP for 1_1 = 0.4616
AP for 1_2 = 0.7060
AP for 1_3 = 0.8937
AP for 2_2 = 0.6699
AP for 2_3 = 0.7823
AP for 3_3 = 0.9114
Mean AP = 0.7375

[14.1]
reduce RPN_MIN_SIZE to 4
skip fc6 and fc7, after 65K iterations
AP for 1_1 = 0.8088
AP for 1_2 = 0.6969
AP for 1_3 = 0.8922
AP for 2_2 = 0.7113
AP for 2_3 = 0.7184
AP for 3_3 = 0.8847
Mean AP = 0.7854

after 80K Iterations
AP for 1_1 = 0.8068
AP for 1_2 = 0.7099
AP for 1_3 = 0.8972
AP for 2_2 = 0.7165
AP for 2_3 = 0.7041
AP for 3_3 = 0.8878
Mean AP = 0.7870

after 80K iterations, TEST.RPN_POST_NMS_TOP_N = 30
AP for 1_1 = 0.8060
AP for 1_2 = 0.7116
AP for 1_3 = 0.8886
AP for 2_2 = 0.7243
AP for 2_3 = 0.7165
AP for 3_3 = 0.8921
Mean AP = 0.7899

after 105K, TEST.RPN_POST_NMS_TOP_N = 30
AP for 1_1 = 0.7951
AP for 1_2 = 0.6762
AP for 1_3 = 0.8907
AP for 2_2 = 0.7084
AP for 2_3 = 0.7395
AP for 3_3 = 0.8844
Mean AP = 0.7824

140K iterations, TEST.RPN_POST_NMS_TOP_N = 5
AP for 1_1 = 0.8245
AP for 1_2 = 0.6901
AP for 1_3 = 0.8837
AP for 2_2 = 0.7461
AP for 2_3 = 0.7349
AP for 3_3 = 0.8794
Mean AP = 0.7931

[15]
The same as [14] but do not load pretrained weights for fc6 and fc7 (Skipping)
70k iterations
AP for 1_1 = 0.5043
AP for 1_2 = 0.7019
AP for 1_3 = 0.8868
AP for 2_2 = 0.6430
AP for 2_3 = 0.7432
AP for 3_3 = 0.8831
Mean AP = 0.7270

140 iterations, LR starting at 0.0001/2 = 0.00005
AP for 1_1 = 0.4405
AP for 1_2 = 0.7017
AP for 1_3 = 0.8935
AP for 2_2 = 0.7011
AP for 2_3 = 0.7337
AP for 3_3 = 0.8968
Mean AP = 0.7279

[16]
The same as 14.1 but with a new channel from IR images!
The data is produced by  prepare_data.mix_radio_ir_train16()

[17]
The same as [16], but with IR inserted as:
0 Blue = radio [0], 1 Green = radio [1], 2 Red = IR[1]

[18]
The same as [16], but with IR inserted as:
0 Blue = radio[0], 1 Green = radio [1], 2 Red = IR[1] + Radio [2]
