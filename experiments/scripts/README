[First]
132 x 132 png files, WITHOUT any standalone '1_x' images
==========================
png pixel size 132
train_size 3730
test_size 3169
anchor_size [8, 16, 32]
feature stride size [16,]
logfile slurm-2153455.out, slurm-2155783.out, slurm-2156848.out

[Second]
132 x 132 png files, plus additional 3845 standalone '1_x' images,
all of which are added to the training set (trainsecond.txt). Thus,
trainsecond.txt = train.txt + additional_3845
The testing set remains the same (test.txt)
==========================
png pixel size 132
train_size 3730 + 3845 = 7575
test_size 3169
anchor_size [8, 16, 32]
feature stride size [16,]
logfile slurm-2160201.out, slurm-2163383.out

[Third]
132 x 132 png files, plus additional 3845 '1_x' images, 2411 of which are added
to the training set (trainthird.txt), and 1434 of which are added to the
testing set (testthird.txt).
==========================
png pixel size 132
train_size 3730 + 2411 = 6141
test_size 3169 + 1434 = 4603
anchor_size [8, 16, 32]
feature stride size [16,]
logfile slurm-2163554.out, slurm-2164344.out

[Thirdsmall]
The same as [Third] except that using a smaller anchor scale and a smaller
feature stride size. Training set becomes (trainthirdsmall.txt), which is just
a symbolic link pointing to trainthird.txt. The reason is only to make the name
different to the system. Testing set (testthirdsmall.txt) is also a symbolic
link to testthird.txt
============================
png pixel size 132
train_size 3730 + 2411 = 6141
test_size 3169 + 1434 = 4603
anchor_size [2, 4, 8]
feature stride size [4,]
logfile slurm-2164121.out, slurm-2165140.out
no result

[Fourth]
500 x 500 png files, plus additional 3845 '1_x' images, 2411 of which are added
to the training set (trainfourth.txt), and 1434 of which are added to the
testing set (trainfourth.txt).
============================
png pixel size 500
train_size 3730 + 2411 = 6141
test_size 3169 + 1434 = 4603
anchor_size [8, 16, 32]
feature stride size [16,]

AP for 1_1 = 0.5265
AP for 1_2 = 0.1275
AP for 1_3 = 0.1919
AP for 2_2 = 0.4597
AP for 2_3 = 0.4076
AP for 3_3 = 0.5094
Mean AP = 0.3704
~~~~~~~~
Results:
0.527
0.127
0.192
0.460
0.408
0.509
0.370
~~~~~~~~

[Fifth]
132 png files
components-based bbox,
change config to 132 x 132
70000 iterations
No result
anchor_size [2, 4, 8]
feature stride size [16,]

[Sixth]
132 png files
anchor_size [2, 4, 8]
feature stride size [16,]
ra-dec bbox,
change config to 132 x 132
140000 iterations
No result

[07]
132 png file
anchor_size [8, 16, 32]
feature stride size [16,]
used the ra-dec bbox with adjustment
trainable = True for low-level ConvNets
but change the side back to s=600
currently in the third round of training after (110K iterations, 24 hours)

test07_2nd (110k iterations)
AP for 1_1 = 0.3915
AP for 1_2 = 0.4812
AP for 1_3 = 0.7695
AP for 2_2 = 0.4841
AP for 2_3 = 0.4449
AP for 3_3 = 0.6207
Mean AP = 0.5320

test07_3rd (160k iterations)
AP for 1_1 = 0.3914
AP for 1_2 = 0.4932
AP for 1_3 = 0.7830
AP for 2_2 = 0.4880
AP for 2_3 = 0.4913
AP for 3_3 = 0.4794
Mean AP = 0.5210

[08]
change side to s=132 again
anchor_size [2, 4, 8]
feature stride size [16,]
It still uses z-scale

[09]
s=600
THe same as 07 except it uses logminmax scaled png directly from FITS
After 55K iterations
AP for 1_1 = 0.3769
AP for 1_2 = 0.5523
AP for 1_3 = 0.7012
AP for 2_2 = 0.3207
AP for 2_3 = 0.4410
AP for 3_3 = 0.6884
Mean AP = 0.5134

[10]
change to the new mean based on log_minmax scale  (235, 128, 24)
similar to 09, it uses log_minmax scaled png
similar to 08, it uses s=132
Does not work!

[11]
The same as 10, BUT with s=600
AP for 1_1 = 0.3701
AP for 1_2 = 0.4665
AP for 1_3 = 0.6128
AP for 2_2 = 0.2377
AP for 2_3 = 0.4292
AP for 3_3 = 0.6339
Mean AP = 0.4584

[12]
The same as 11, BUT
anchor_scales=[1, 2, 4, 8, 16, 32]
anchor_ratios=[1]
RPN_BATCHSIZE is still 256
55K iterations:
-------------------
AP for 1_1 = 0.5186
AP for 1_2 = 0.5417
AP for 1_3 = 0.6363
AP for 2_2 = 0.3562
AP for 2_3 = 0.4369
AP for 3_3 = 0.5244
Mean AP = 0.5023

105K Iterations (with a starting LR 0.001 for the second round)
-------------------
AP for 1_1 = 0.2887
AP for 1_2 = 0.6552
AP for 1_3 = 0.7526
AP for 2_2 = 0.5021
AP for 2_3 = 0.5364
AP for 3_3 = 0.7506
Mean AP = 0.5809

100K Iterations (with a starting LR 0.0001 for the second round)
???

[13]
The same as [12] but loading the original VGGnet feature ConvNet
low_level_trainable is still TRUE

[14]
The same as [13] but loading the original VGGnet feature ConvNet
low_level_trainable is set to FALSE
